{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  \\\n",
    "    langchain-pinecone \\\n",
    "    langchain-openai \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    pinecone-notebooks\\\n",
    "!pip uninstall -y ragas\n",
    "!pip install -q pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\Downloads\\\\ten_academy\\\\week7\\\\Precision-RAG-For_Enterprise-Grade-RAG-Systems'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_loader = PyPDFLoader(\"./data/10 Academy Cohort B - Weekly Challenge_ Week - 7.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = directory_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split docs 24\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(raw)\n",
    "print('split docs', len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_INDEX_NAME = \"pdf-doc\"\n",
    "PINECONE_NAME_SPACE = \"pdf-namespace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = PINECONE_INDEX_NAME  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 48}},\n",
       " 'total_vector_count': 48}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deliverables\n",
      "NOTE:\n",
      "Document\n",
      "should\n",
      "be\n",
      "a\n",
      "PDF\n",
      "stored\n",
      "in\n",
      "google\n",
      "drive\n",
      "or\n",
      "published\n",
      "blog\n",
      "link.\n",
      "DO\n",
      "NOT\n",
      "SUBMIT\n",
      "A\n",
      "LINK\n",
      "as\n",
      "PDF!\n",
      "If\n",
      "you\n",
      "want\n",
      "to\n",
      "submit\n",
      "pdf\n",
      "document,\n",
      "it\n",
      "should\n",
      "be\n",
      "the\n",
      "content\n",
      "of\n",
      "your\n",
      "report\n",
      "not\n",
      "a\n",
      "link.\n",
      "Interim\n",
      "Submission\n",
      "-\n",
      "Wednesday\n",
      "8pm\n",
      "UTC\n",
      "●\n",
      "Link\n",
      "to\n",
      "your\n",
      "code\n",
      "in\n",
      "GitHub\n",
      "○\n",
      "Repository\n",
      "where\n",
      "you\n",
      "will\n",
      "be\n",
      "using\n",
      "to\n",
      "complete\n",
      "the\n",
      "tasks\n",
      "in\n",
      "this\n",
      "week's\n",
      "challenge.\n",
      "A\n",
      "minimum\n",
      "requirement\n",
      "is\n",
      "that\n",
      "you\n",
      "have\n",
      "a\n",
      "well\n",
      "structured\n",
      "repository\n",
      "and\n",
      "some\n",
      "coding\n",
      "progress\n",
      "is\n",
      "made.\n",
      "●\n",
      "A\n",
      "review\n",
      "report\n",
      "of\n",
      "your\n",
      "reading\n",
      "and\n",
      "understanding\n",
      "of\n",
      "Task\n",
      "1\n",
      "and\n",
      "any\n",
      "progress\n",
      "you\n",
      "made\n",
      "in\n",
      "other\n",
      "tasks.\n",
      "Feedback\n",
      "You\n",
      "may\n",
      "not\n",
      "receive\n",
      "detailed\n",
      "comments\n",
      "on\n",
      "your\n",
      "interim\n",
      "submission\n",
      "but\n",
      "will\n",
      "receive\n",
      "a\n",
      "grade.\n",
      "Final\n",
      "Submission\n",
      "-\n",
      "Saturday\n",
      "8pm\n",
      "UTC\n",
      "●\n",
      "Link\n",
      "to\n",
      "your\n",
      "code\n",
      "in\n",
      "GitHub\n",
      "○\n",
      "Complete\n",
      "work\n",
      "for\n",
      "Automatic\n",
      "prompt\n",
      "generation\n",
      "○\n",
      "Complete\n",
      "work\n",
      "for\n",
      "Automatic\n",
      "evaluation\n",
      "○\n",
      "Complete\n",
      "work\n",
      "for\n",
      "Evaluation\n",
      "Data\n",
      "Generation\n",
      "●\n",
      "A\n",
      "blog\n",
      "post\n",
      "entry\n",
      "(which\n",
      "you\n",
      "can\n",
      "submit\n",
      "for\n",
      "example\n",
      "to\n",
      "Medium\n",
      "publishing)\n",
      "or\n",
      "a\n",
      "pdf\n",
      "report.\n",
      "Feedback\n",
      "You\n",
      "will\n",
      "receive\n"
     ]
    }
   ],
   "source": [
    "query = \"When is the submission deadline for interim report?\"\n",
    "docs_10 = docsearch.similarity_search(query)\n",
    "print(docs_10[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Downloads\\ten_academy\\week7\\Precision-RAG-For_Enterprise-Grade-RAG-Systems\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=\"\",\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant. that generates a good prompt for the given context and \\\n",
    "                  if you do not have context you replay with I do not have context.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = docsearch.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the tasks for the week?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_prompt_txt = augment_prompt(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(augment_prompt_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tasks for the week include:\n",
      "- Understanding the week's challenge\n",
      "- Understanding prompt engineering\n",
      "- Understanding Prompt ranking\n",
      "- Understanding prompt matching\n",
      "- RAG components\n",
      "- Techniques to improve R in RAG\n",
      "- RAG Evaluation Data Generation\n",
      "- Understanding prompt matching and ranking\n",
      "- RAG evaluation metrics\n",
      "- RAGOps - DevOps of RAG development and production deployment\n",
      "\n",
      "These tasks are part of the training program agenda for the week.\n"
     ]
    }
   ],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt_txt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
